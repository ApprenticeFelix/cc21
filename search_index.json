[["index.html", "Spring 2021 EDAV Community Contributions Chapter 1 Community contribution assignment 1.1 Logistics", " Spring 2021 EDAV Community Contributions 2021-03-25 Chapter 1 Community contribution assignment This fairly open-ended assignment provides an opportunity to receive credit for contributing to the collective learning of the class, and perhaps beyond. It should reflect a minimum of 2-3 hours of work. To complete the assignment you must submit a short description of your contribution. If appropriate, attach relevant files. There are many ways in which you can contribute: lead a Zoom conversation on anything: hobby, happy hour, etc. Think about how you will organize it… do students need to sign up? Will you have breakout rooms? help students find final project partners give a well-rehearsed 5 minute lightning talk in class on a datavis topic (theory or tool) (email me to set the date – it may be after the assignment due date but you need to schedule it before) create a video tutorial (any length) create a cheatsheet or other resource be a Piazza super user (that is, answer a lot of questions) write a tutorial for a tool that’s not well documented translate a useful resource into another language build a viz product (ex. htmlwidget) for class use create a web site for sharing class resources publicly provide significant subject matter help to a classmate organize and lead a help session on a particular topic (the date may be after the assignment due date but you need to schedule it before) [your own idea] You may draw on and expand existing resources. When doing so, it is critical that you cite your sources. Examples from last year: https://jtr13.github.io/cc20/ 1.1 Logistics 1.1.1 Groups You may work on your own or with a partner of your choosing. If you work alone, you do not need to join a group of 1, you simply submit your work on CourseWorks as with any other solo assignment. If you work with a partner, add yourselves to a group on the CC page on the People tab. Piazza can be used to find partners with similar interests. 1.1.2 Submitting your assignment You must submit your assignment twice: once on CourseWorks (so it can be graded) and once to the class, details to follow. CourseWorks submission: submit your work as an .Rmd and rendered .pdf or .html file, just as with problem sets. If your work does not lend itself to that format, then write in the assignment text box what you did. Class (GitHub) submission: see the next chapter. "],["github-submission-instructions.html", "Chapter 2 GitHub submission instructions 2.1 Background 2.2 Preparing your .Rmd file 2.3 Submission steps 2.4 Optional tweaks 2.5 FAQ", " Chapter 2 GitHub submission instructions This chapter gives you all the information you need to upload your community contribution. Please read this entire document carefully before making your submission. Of particular note is the fact that bookdown requires a different .Rmd format than you’re used to, so you must make changes to the beginning of the file as described below before submitting. 2.1 Background This web site makes use of the bookdown package to render a collection of .Rmd files into a nicely formatted online book with chapters and subchapters. Your job will be to submit a slightly modified version of your community contribution .Rmd file to the GitHub repository where the source files for this web site are stored. On the backend, the admins will divide the chapters into book sections and order them. If your community contribution is in a different format, then create a short .Rmd file that explains what you did, and includes links to any relevant files, such as slides, etc. which you can post on your GitHub repo (or another online site.) 2.2 Preparing your .Rmd file You should only submit ONE Rmd file. After completing these modifications, your .Rmd should look like this sample .Rmd. Create a concise, descriptive name for your project. For instance, name it base_r_ggplot_graph or something similar if your work is about contrasting/working with base R graphics and ggplot2 graphics. Check the .Rmd filenames in the project repo to make sure your name isn’t already taken. Your project name should be words only and joined with underscores, no white space. Use .Rmd not .rmd. In addition, all letters must be lowercase. Create a copy of your .Rmd file with the new name. Completely delete the YAML header (the section at the top of the .Rmd that includes name, title, date, output, etc.) including the --- line. Choose a short, descriptive, human readable title for your project as your title will show up in the table of contents – look at examples in the 2020 EDAV rendered book of community contributions https://jtr13.github.io/cc20. Capitalize the first letter only (“sentence case”). On the first line of your document, enter a single hashtag, followed by a single whitespace, and then your title. It is important to follow this format so that bookdown renders your title as a header. Do not use single # headers anywhere else in the document. Note: if your chapter is the first in a section, a second # header and section description will be requested during the pull-request and merge phase. The second line should be blank, followed by your name(s): # Base R vs. ggplot2 Aaron Burr and Alexander Hamilton Your content starts here. If your project requires data, please use a built-in dataset or read directly from a URL, such as: df &lt;- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\") If you absolutely must include a data file, please use a small one, as for many reasons it is desirable to keep the repository size as small as possible. If you have included a setup chunk in your Rmd file, please remember to remove the label setup in the chunk, i.e., use: {r, include=FALSE} instead of: {r setup, include=FALSE} If your project requires libraries to be installed and included in the document, please adhere to the following conventions. Do not evaluate any install.packages() statements in your document. Consumers of an .Rmd file won’t want packages to get installed when they knit your document. Include any library() statements at the top of your Rmd file, below the title, name, and setup, but above any content. If your chapter requires the installation of a package from source (is a GitHub installation), please add a comment identifying it as such. Please mention this as well in your PR. Here is an example library() section with install statements that won’t be evaluated: install.packages(&quot;devtools&quot;) # used for installation from source install.packages(&quot;dplyr&quot;) install.packages(&quot;ggplot2&quot;) library(&quot;devtools&quot;) devtools::install_github(&quot;twitter/AnomalyDetection&quot;) library(&quot;AnomalyDetection&quot;) # must be installed from source library(&quot;dplyr&quot;) library(&quot;ggplot2&quot;) You could include both sections, or you could just include the second library() section and trust R users to install any packages themselves. If you developed your Rmd file before moving your library() statements above the rest of the file content, it is highly recommended to knit and review your document again. This may change the namespace that was available in each section of your code during development, causing a function not to work or to exhibit unexpected behavior. This common issue is mentioned in the EDAV R Basics “Functions stop working” section. Your file should not contain getwd() / setwd() calls (you should never use these in scripts anyway!) nor write statements. Want to get fancy? See the optional tweaks section below. 2.3 Submission steps To submit your work, we will be following “Workflow #4” – that is submitting a pull request to someone else’s repository to which you do not have write access. Instructions are available in this tutorial. They are repeated below in abbreviated form, with specific instructions on naming conventions, content information, and other important details. Fork cc21 repo (this repo) to your GitHub account. Clone/download the forked repo to your local computer. Create a new branch and name it with your project name, in our case sample_project. Do not skip this step. We will not merge your PR if it doesn’t come from a branch. If you already forgot to do this, check this tutorial for how to fix it. Copy your modified .Rmd file with the same name into the root directory on the branch. In our example, it is sample_project.Rmd. Do not include an .html file. (In order for the bookdown package to work, all .Rmd files will be rendered behind the scenes.) [OPTIONAL] If you have other resources (such as images) included in your project, create a folder under resources/. In our example, it is resources/sample_project/. Put the resources files there. Be sure to change all the links in your .Rmd to include resources/.../, for example: ![Test Photo](resources/sample_project/election.jpg) When you are ready to submit your project, push your branch to your remote repo. Follow this tutorial to create a pull request. At this point a back and forth will begin with the team managing the pull requests. If you are asked to make changes, simply make the changes on your local branch, save, commit, and push to GitHub. The new commits will be added to your pull request; you do not need to, and should not, create a new pull request. (If, based on the circumstances, it does make sense to close the pull request and start a new one, we will tell you.) Once your pull request is merged, it’s fine to delete your local clone (folder) as well as the forked repository in your GitHub account. 2.4 Optional tweaks If you prefer for links from your chapter to open in new tabs, add {target=\"_blank\"} after the link, such as: [edav.info](edav.info){target=\"_blank\"} Note that your headers (##, ###, etc.) will be converted to numbered headings as such: ## –&gt; 3.1 ### –&gt; 3.1.1 These headings will appear as chapter subheadings and sub-subheadings in the navigation panel on the left. Think about a logical structure for users to navigate your chapter. We recommend using only ## and ### headings since “sub-sub-subheadings” such as 4.1.3.4 are generally unnecessary and look messy. Unfortunately, there’s no simple way to preview your chapter before it’s actually merged into the project. (bookdown has preview_chapter() option but it only works after the entire book has been rendered at least once and that will become more and more complex and require more and more packages as the project grows.) If you really want to preview it, fork and clone this minimal bookdown repo, add your .Rmd file, click the “Build book” button on the Build tab (next to Git), and then open any of the .html files in the _book folder in a web browser to see the rendered book. If you’re interested in more bookdown options, see the official reference book. Have more useful tweaks to share? Submit an issue or PR. 2.5 FAQ 2.5.1 What should I expect after creating a pull request? Within a week after you create a pull request, we will apply a label to it and assign an administrator who will review all the files you submit to see if they meet the requirements. It will take some time before we can process all the pull requests, so as long as you see your pull request has been labeled and assigned to an admin, don’t worry. However, if the admin contacts you regarding the pull request, that usually means your files fail to meet some requirements. The admin will clearly state what is wrong, so please fix them as soon as possible. 2.5.2 What if I catch mistakes before my pull request is merged? Just make the changes on your branch, commit and push them to GitHub. They will automatically be added to the pull request. 2.5.3 What if I catch mistakes after my pull request is merged? You may submit additional pull requests to fix material on the site. If the edits are small, such as fixing typos, it is easiest to make the edits directly on GitHub, following these instructions. We will merge first pull requests before edits, so please be patient. 2.5.4 Other questions If you encounter other problems, please submit an issue and we will look into it. Thank you for your contributions! "],["sample-project.html", "Chapter 3 Sample project", " Chapter 3 Sample project Joe Biden and Donald Trump This chapter gives a sample layout of your Rmd file. Test Photo "],["introduction-to-quandl.html", "Chapter 4 Introduction to Quandl() 4.1 INTRODUCTION", " Chapter 4 Introduction to Quandl() Aiqi Zhou (az2638) Quandl::Quandl() 4.1 INTRODUCTION Quandl is a source of financial, economic and alternative data. It is acquired by Nasdaq in 2018 and has 20+ million data sets available. Users can acquire free data, purchase data or sell data at Quandl. You can find data on a large variety of types of data from company data to the demographics data of a country. More can be explored on Quandl’s website. https://www.quandl.com/search The data is readily available in json, csv, xml formats and can be loaded in MatLab, R, Python, etc. All the data can be loaded in R through the package Quandl. 4.1.1 Installation : install.packages(“Quandl”) 4.1.2 Load Package library(Quandl) library(Quandl) 4.1.3 Set API key Quandl allows 50 calls a day for anonymous users. Sign up for a free account to make unlimited calls every day. Set up your own account and copy your api_key into the following function Quandl.api_key(‘your_key’) Quandl.api_key(&#39;JrvHzZcnakybdzAUChjn&#39;) 4.1.4 Loading Data All available data can be found and viewed on https://www.quandl.com/search. This package includes many free datasets, however, some datasets requires an account or is for paid use only. To call on a data set in R. You must find the Quandl code of the data set. The codes can be found in the documentation page of the data set. 4.1.4.1 For example The follow dataset is called the “Federal Reserve Economic Data”, which has the code FRED. This dataset has 335,000+ time-series data. To call on certain aspect like the GDP of this data set, the Quandl code is “FRED/GDP”. mydata = Quandl(&quot;FRED/GDP&quot;) head(mydata) ## Date Value ## 1 2020-10-01 21487.90 ## 2 2020-07-01 21170.25 ## 3 2020-04-01 19520.11 ## 4 2020-01-01 21561.14 ## 5 2019-10-01 21747.39 ## 6 2019-07-01 21540.33 To call on another aspect like disposable personal income, the Quandl code is “FRED/DSPI” mydata= Quandl(&quot;FRED/DSPI&quot;) head(mydata) ## Date Value ## 1 2021-01-01 19217.7 ## 2 2020-12-01 17254.5 ## 3 2020-11-01 17151.4 ## 4 2020-10-01 17398.9 ## 5 2020-09-01 17546.8 ## 6 2020-08-01 17430.4 4.1.5 Type The data can be called in different formats. The default of the data is data frame, which can have an argument type = “raw” “raw” “ts” “zoo” “xts” “timeSeries” mydata = Quandl(&quot;FRED/GDP&quot;, type=&quot;xts&quot;) head(mydata) ## [,1] ## 1947 Q1 243.164 ## 1947 Q2 245.968 ## 1947 Q3 249.585 ## 1947 Q4 259.745 ## 1948 Q1 265.742 ## 1948 Q2 272.567 mydata = Quandl(&quot;FRED/GDP&quot;, type=&quot;ts&quot;) head(mydata) ## [1] 243.164 245.968 249.585 259.745 265.742 272.567 mydata = Quandl(&quot;FRED/GDP&quot;, type=&quot;zoo&quot;) head(mydata) ## 1947 Q1 1947 Q2 1947 Q3 1947 Q4 1948 Q1 1948 Q2 ## 243.164 245.968 249.585 259.745 265.742 272.567 4.1.6 Transform There are some preprocessing can be done when loading the data. By adding a transform argument in Quandl(), the data can have the following types of transformations. \"\" = Default original data “diff” = row on row change in value “rdiff” = row on row percentage change “normalize” = scale to start at 100 “cumul” = cumulative sum “rdiff_from” = latest value as % increment 4.1.6.1 For example the percentage change of GDP by year mydata = Quandl(&quot;FRED/GDP&quot;,transform = &quot;rdiff&quot; ) head(mydata) ## Date Value ## 1 2020-10-01 0.015004262 ## 2 2020-07-01 0.084535264 ## 3 2020-04-01 -0.094662207 ## 4 2020-01-01 -0.008564474 ## 5 2019-10-01 0.009613086 ## 6 2019-07-01 0.009866349 4.1.7 Order The data can be ordered by date upon it is loaded. Default is descending order by date. - “desc” - “asc” mydata = Quandl(&quot;FRED/GDP&quot;, order = &quot;asc&quot;) head(mydata) ## Date Value ## 1 1947-01-01 243.164 ## 2 1947-04-01 245.968 ## 3 1947-07-01 249.585 ## 4 1947-10-01 259.745 ## 5 1948-01-01 265.742 ## 6 1948-04-01 272.567 4.1.8 collapse Since all data have a time associated. Quandl allows you to preprocess the data by specifying the frequency of the data. ’’ ‘daily’ ‘weekly’ ‘monthly’ ‘quarterly’ ‘annual’ mydata = Quandl(&quot;FRED/GDP&quot;, collapse = &quot;quarterly&quot;) head(mydata) ## Date Value ## 1 2020-12-31 21487.90 ## 2 2020-09-30 21170.25 ## 3 2020-06-30 19520.11 ## 4 2020-03-31 21561.14 ## 5 2019-12-31 21747.39 ## 6 2019-09-30 21540.33 4.1.9 Slicing data 4.1.9.1 Rows Because the data we are using is time series data, we can specify the range of row of the data set, using the start and end date arguments. mydata = Quandl(&quot;FRED/GDP&quot;, start_date=&quot;2001-12-31&quot;, end_date=&quot;2005-12-31&quot;) head(mydata) ## Date Value ## 1 2005-10-01 13332.32 ## 2 2005-07-01 13142.87 ## 3 2005-04-01 12910.02 ## 4 2005-01-01 12761.34 ## 5 2004-10-01 12522.42 ## 6 2004-07-01 12303.34 4.1.9.2 Columns To get multiple columns of data from Quandl, the data can be called in the format: Quandl(c(“col_1”, “col_2”)) mydata = Quandl(c(&quot;FRED/GDP&quot;, &quot;FRED/DSPI&quot;),start_date=&quot;2001-12-31&quot;, end_date=&quot;2005-12-31&quot;) head(mydata) ## Date FRED.GDP - Value FRED.DSPI - Value ## 1 2002-01-01 10788.95 7962.4 ## 2 2002-02-01 NA 7981.9 ## 3 2002-03-01 NA 8003.6 ## 4 2002-04-01 10893.21 8066.8 ## 5 2002-05-01 NA 8099.5 ## 6 2002-06-01 NA 8127.2 4.1.10 Finding a dataset in Quandl You can look for certain data sets within R using Quandl.search() Format: Quandl.search(query = “search keyword”, page = # , source = “source to search from if known”, silent = TRUE/FALSE) query: mandatory argument that you want to search for page: which page of search result you want. Default page = 1. source: specific source you want to search from. silent: print the results when FALSE. Nothing prints when true. 4.1.10.1 Example search for Japan Quandl.search(query = &quot;Japan&quot;, page = 1 , silent = FALSE) ## Japanese Intervention: Japanese Bank purchases of USD against JPY ## Code: FRED/JPINTDUSDJPY ## Desc: 100 Million Yen Not Seasonally Adjusted, (+) numbers mean purchases of the USD (sell Yen), (-) numbers mean sales of USD (buy Yen). Unpublished data. ## Freq: daily ## Cols: DATE | VALUE ## ## NASDAQ Japan Retail JPY Index (NQJP5300JPY) ## Code: NASDAQOMX/NQJP5300JPY ## Desc: For detailed information, see &lt;a href=https://indexes.nasdaqomx.com/Index/Overview/NQJP5300JPY&gt;https://indexes.nasdaqomx.com/Index/Overview/NQJP5300JPY&lt;/a&gt; ## Freq: daily ## Cols: Trade Date | Index Value | High | Low | Total Market Value | Dividend Market Value ## ## NASDAQ Japan Media JPY Index (NQJP5500JPY) ## Code: NASDAQOMX/NQJP5500JPY ## Desc: For detailed information, see &lt;a href=https://indexes.nasdaqomx.com/Index/Overview/NQJP5500JPY&gt;https://indexes.nasdaqomx.com/Index/Overview/NQJP5500JPY&lt;/a&gt; ## Freq: daily ## Cols: Trade Date | Index Value | High | Low | Total Market Value | Dividend Market Value ## ## NASDAQ Japan Tech JPY Index (NQJP9000JPY) ## Code: NASDAQOMX/NQJP9000JPY ## Desc: For detailed information, see &lt;a href=https://indexes.nasdaqomx.com/Index/Overview/NQJP9000JPY&gt;https://indexes.nasdaqomx.com/Index/Overview/NQJP9000JPY&lt;/a&gt; ## Freq: daily ## Cols: Trade Date | Index Value | High | Low | Total Market Value | Dividend Market Value ## ## NASDAQ Japan Telecom JPY Index (NQJP6000JPY) ## Code: NASDAQOMX/NQJP6000JPY ## Desc: For detailed information, see &lt;a href=https://indexes.nasdaqomx.com/Index/Overview/NQJP6000JPY&gt;https://indexes.nasdaqomx.com/Index/Overview/NQJP6000JPY&lt;/a&gt; ## Freq: daily ## Cols: Trade Date | Index Value | High | Low | Total Market Value | Dividend Market Value ## ## NASDAQ Japan Utilities JPY Index (NQJP7000JPY) ## Code: NASDAQOMX/NQJP7000JPY ## Desc: For detailed information, see &lt;a href=https://indexes.nasdaqomx.com/Index/Overview/NQJP7000JPY&gt;https://indexes.nasdaqomx.com/Index/Overview/NQJP7000JPY&lt;/a&gt; ## Freq: daily ## Cols: Trade Date | Index Value | High | Low | Total Market Value | Dividend Market Value ## ## NASDAQ Japan Banks JPY Index (NQJP8300JPY) ## Code: NASDAQOMX/NQJP8300JPY ## Desc: For detailed information, see &lt;a href=https://indexes.nasdaqomx.com/Index/Overview/NQJP8300JPY&gt;https://indexes.nasdaqomx.com/Index/Overview/NQJP8300JPY&lt;/a&gt; ## Freq: daily ## Cols: Trade Date | Index Value | High | Low | Total Market Value | Dividend Market Value ## ## NASDAQ Japan Inds JPY Index (NQJP2000JPY) ## Code: NASDAQOMX/NQJP2000JPY ## Desc: For detailed information, see &lt;a href=https://indexes.nasdaqomx.com/Index/Overview/NQJP2000JPY&gt;https://indexes.nasdaqomx.com/Index/Overview/NQJP2000JPY&lt;/a&gt; ## Freq: daily ## Cols: Trade Date | Index Value | High | Low | Total Market Value | Dividend Market Value ## ## NASDAQ Japan Ins JPY Index (NQJP8500JPY) ## Code: NASDAQOMX/NQJP8500JPY ## Desc: For detailed information, see &lt;a href=https://indexes.nasdaqomx.com/Index/Overview/NQJP8500JPY&gt;https://indexes.nasdaqomx.com/Index/Overview/NQJP8500JPY&lt;/a&gt; ## Freq: daily ## Cols: Trade Date | Index Value | High | Low | Total Market Value | Dividend Market Value ## ## NASDAQ Japan Financials JPY Index (NQJP8000JPY) ## Code: NASDAQOMX/NQJP8000JPY ## Desc: For detailed information, see &lt;a href=https://indexes.nasdaqomx.com/Index/Overview/NQJP8000JPY&gt;https://indexes.nasdaqomx.com/Index/Overview/NQJP8000JPY&lt;/a&gt; ## Freq: daily ## Cols: Trade Date | Index Value | High | Low | Total Market Value | Dividend Market Value You can pick which data set to use from the search result. 4.1.11 Example The following is a quick example of getting data from the data set United Nations Industrial Commodities. From the documentation of this data set, we can learn what we are interested in. https://www.quandl.com/data/UINC-United-Nations-Industrial-Commodities Here I want to plot the time series data of Beer production of Germany. The code for this information is “UINC/BEER_DEU”. I want to plot the time series, then the data need to be in the form of “ts” beer = Quandl(&quot;UINC/BEER_DEU&quot;,type = &quot;ts&quot;) head(beer) ## Beer (Mil. USD) Beer (Thousand hectolitres) ## [1,] 10021.504 111875.4 ## [2,] 9468.029 108937.5 ## [3,] 8258.888 108729.5 ## [4,] 7873.553 106993.0 ## [5,] 7625.868 107479.3 ## [6,] 6420.827 106877.4 beer = Quandl(&quot;UINC/BEER_DEU&quot;,type = &quot;ts&quot;) plot.ts(beer) If I want to see the yearly percentage change of the data, we need to add a transform argument “rdiff” beer_per_change = Quandl(&quot;UINC/BEER_DEU&quot;,type = &quot;ts&quot;,transform = &#39;rdiff&#39;) plot.ts(beer_per_change) "],["date-time-handling-in-r-cheatsheet.html", "Chapter 5 Date-Time Handling in R Cheatsheet", " Chapter 5 Date-Time Handling in R Cheatsheet Saloni Gupta Ajay Kumar This project includes a pdf version cheatsheet for basic date-time handling in R. This includes conversion to Date and Datetime objects, extraction of date elements, date arithmetic and time zone conversions. Click the following link to check out the cheatsheet: https://github.com/C130187/EDAVCC/blob/main/DateTime-cheatsheet-in-R.pdf "],["tidy-data-cheatsheet.html", "Chapter 6 Tidy data Cheatsheet", " Chapter 6 Tidy data Cheatsheet Yifan Jing This project includes a pdf version cheatsheet for tidy data. It includes functions in tidyr and dplyr. The link is below: https://github.com/JackJing001/STAT5702/blob/main/Tidy%20data%20cheat%20sheet.pdf "],["ggvis-cheatsheet.html", "Chapter 7 GGvis cheatsheet 7.1 ggvis 7.2 aesthetics 7.3 Interaction 7.4 Layers", " Chapter 7 GGvis cheatsheet Chenhui Mao Link to the cheatsheet 7.1 ggvis Official website: http://ggvis.rstudio.com/ ggvis is a visualization package that can: - plot the graph in the same way as ggplot2 - create interaction strategies where you can interact with the graph locally or in the website 7.1.1 Getting start First thing first, we shall import some necessary packages install.packages(&quot;dplyr&quot;) install.packages(&quot;ggvis&quot;) library(ggvis) library(dplyr) This is a simple demonstration on how to use ggvis. As can be seen, ggvis can create graph in the same way ggplot does! p &lt;- ggvis(mtcars, x = ~wt, y = ~ mpg) layer_points(p) Renderer: SVG | Canvas Download Similar way to write basic ggvis layer_points(ggvis(mtcars, x = ~wt, y = ~ mpg)) Renderer: SVG | Canvas Download Apply pipeline to write ggvis mtcars %&gt;% ggvis(x = ~wt, y = ~mpg) %&gt;% layer_points Renderer: SVG | Canvas Download We can add a theme on it mtcars %&gt;% ggvis(x = ~wt, y = ~mpg) %&gt;% layer_points() %&gt;% add_axis(&quot;x&quot;, title = &quot;Weight&quot;, ticks = 40, properties = axis_props( ticks = list(stroke = &quot;red&quot;), majorTicks = list(strokeWidth = 2), grid = list(stroke = &quot;red&quot;), labels = list( fill = &quot;steelblue&quot;, angle = 50, fontSize = 14, align = &quot;left&quot;, baseline = &quot;middle&quot;, dx = 3 ), title = list(fontSize = 16), axis = list(stroke = &quot;#333&quot;, strokeWidth = 1.5) ) ) Renderer: SVG | Canvas Download 7.2 aesthetics Try to adjust the parameters mtcars %&gt;% ggvis(~mpg, ~disp, stroke = ~vs) %&gt;% layer_points() Renderer: SVG | Canvas Download mtcars %&gt;% ggvis(~mpg, ~disp, fill = ~vs) %&gt;% layer_points() Renderer: SVG | Canvas Download mtcars %&gt;% ggvis(~mpg, ~disp, size = ~vs) %&gt;% layer_points() Renderer: SVG | Canvas Download mtcars %&gt;% ggvis(~mpg, ~disp, shape = ~factor(cyl)) %&gt;% layer_points() Renderer: SVG | Canvas Download mtcars %&gt;% ggvis(~wt, ~mpg, fill := &quot;red&quot;, stroke := &quot;black&quot;) %&gt;% layer_points() Renderer: SVG | Canvas Download mtcars %&gt;% ggvis(~wt, ~mpg, size := 300, opacity := 0.4) %&gt;% layer_points() Renderer: SVG | Canvas Download 7.3 Interaction 7.3.1 basic interaction mtcars %&gt;% ggvis(x = ~wt, y = ~mpg) %&gt;% layer_points() %&gt;% layer_smooths( span = input_slider(0.2, 1, value = 0.5, step = 0.05, label = &quot;span&quot;) ) Renderer: SVG | Canvas Download Next, we add some interaction strategies into it. We can add the following interaction into the graph: - Change the size of the dot - Change the opacity of the dot mtcars %&gt;% ggvis(~wt, ~mpg, size := input_slider(10, 100), opacity := input_slider(0, 1) ) %&gt;% layer_points() Renderer: SVG | Canvas Download Add interaction strategies to a histograms - Change the width of the histograms - Change the center of the histograms mtcars %&gt;% ggvis(~wt) %&gt;% layer_histograms( width = input_slider(0, 2, step = 0.10, label = &quot;width&quot;), center = input_slider(0, 2, step = 0.05, label = &quot;center&quot;)) Renderer: SVG | Canvas Download Add tooltip mtcars %&gt;% ggvis(~wt, ~mpg) %&gt;% layer_points()%&gt;% add_tooltip(function(df) df$wt) Renderer: SVG | Canvas Download 7.3.2 Input option 7.3.2.1 input_select() mtcars %&gt;% ggvis(x = ~wt) %&gt;% layer_densities( adjust = input_slider(.1, 2, value = 1, step = .1, label = &quot;Bandwidth adjustment&quot;), kernel = input_select( c(&quot;Gaussian&quot; = &quot;gaussian&quot;, &quot;Epanechnikov&quot; = &quot;epanechnikov&quot;, &quot;Rectangular&quot; = &quot;rectangular&quot;, &quot;Triangular&quot; = &quot;triangular&quot;, &quot;Biweight&quot; = &quot;biweight&quot;, &quot;Cosine&quot; = &quot;cosine&quot;, &quot;Optcosine&quot; = &quot;optcosine&quot;), label = &quot;Kernel&quot;) ) Renderer: SVG | Canvas Download 7.3.2.2 Checkbox input mtcars %&gt;% ggvis(x = ~wt, y = ~mpg) %&gt;% layer_points( opacity := input_checkbox(label = &quot;Semi-transparent&quot;, map = function(val) ifelse(val, .3, 1))) %&gt;% layer_model_predictions( model = input_checkbox(label = &quot;LOESS (curve) model fit&quot;, map = function(val) ifelse(val, &quot;loess&quot;, &quot;lm&quot;))) Renderer: SVG | Canvas Download 7.3.2.3 Text input mtcars %&gt;% ggvis(x = ~wt, y = ~mpg) %&gt;% layer_points(fill := input_text(label = &quot;Point color&quot;, value = &quot;red&quot;)) %&gt;% layer_model_predictions(model = input_text(label = &quot;Model type&quot;, value = &quot;loess&quot;)) Renderer: SVG | Canvas Download 7.3.2.4 Numeric input mtcars %&gt;% ggvis(x = ~wt, y = ~mpg) %&gt;% layer_points(size := input_numeric(value = 25, label = &quot;Point size&quot;)) %&gt;% layer_smooths(span = input_numeric(value = 0.5, label = &quot;Interpolation points&quot;)) Renderer: SVG | Canvas Download 7.3.2.5 Radio buttons mtcars %&gt;% ggvis(x = ~wt, y = ~mpg) %&gt;% layer_points() %&gt;% layer_model_predictions( model = input_radiobuttons(c(&quot;LOESS&quot; = &quot;loess&quot;, &quot;Linear&quot; = &quot;lm&quot;), label = &quot;Model type&quot;), stroke := input_radiobuttons(c(&quot;Red&quot; = &quot;red&quot;, &quot;Black&quot; = &quot;black&quot;), label = &quot;Line color&quot;) ) Renderer: SVG | Canvas Download 7.3.2.6 Checkbox group mtcars %&gt;% ggvis(x = ~wt, y = ~mpg) %&gt;% layer_points( fill := input_checkboxgroup( choices = c(&quot;Red&quot; = &quot;r&quot;, &quot;Green&quot; = &quot;g&quot;, &quot;Blue&quot; = &quot;b&quot;), label = &quot;Point color components&quot;, map = function(val) { rgb(0.8 * &quot;r&quot; %in% val, 0.8 * &quot;g&quot; %in% val, 0.8 * &quot;b&quot; %in% val) } ) ) Renderer: SVG | Canvas Download 7.3.3 Map 7.3.3.1 Example with value map function mtcars %&gt;% ggvis(x = ~wt, y = ~mpg) %&gt;% layer_points() %&gt;% layer_model_predictions(model = &quot;loess&quot;, model_args = list(n = input_select( choices = c(&quot;Two&quot;, &quot;Six&quot;, &quot;Eighty&quot;), map = function(value) switch(value, Two = 2, Six = 6, Eighty = 80), label = &quot;Number of points&quot; )) ) Renderer: SVG | Canvas Download new_vals &lt;- input_select(c(&quot;Set A&quot; = &quot;A&quot;, &quot;Set B&quot; = &quot;B&quot;), label = &quot;Dynamically-generated column&quot;, map = function(value) { vals &lt;- switch(value, &quot;A&quot; = rep(c(&quot;One&quot;, &quot;Two&quot;)), &quot;B&quot; = c(&quot;First&quot;, &quot;Second&quot;, &quot;Third&quot;, &quot;Fourth&quot;)) rep(vals, length = nrow(mtcars)) }) mtcars %&gt;% ggvis(x = ~wt, y = ~mpg, fill = new_vals) %&gt;% layer_points() Renderer: SVG | Canvas Download mtcars %&gt;% ggvis( x = ~wt, y = ~mpg, fill = input_select(c(&quot;mpg&quot;, &quot;wt&quot;), map = as.name) ) %&gt;% layer_points() Renderer: SVG | Canvas Download 7.4 Layers 7.4.1 Simple layers include primitives like points, lines and rectangles. mtcars %&gt;% ggvis(~wt, ~mpg) %&gt;% layer_points() Renderer: SVG | Canvas Download Paths and polygons df &lt;- data.frame(x = 1:10, y = runif(10)) df %&gt;% ggvis(~x, ~y) %&gt;% layer_paths() Renderer: SVG | Canvas Download If you add fill, you will get a polygon t &lt;- seq(0, 2 * pi, length = 100) df &lt;- data.frame(x = sin(t), y = cos(t)) df %&gt;% ggvis(~x, ~y) %&gt;% layer_paths(fill := &quot;red&quot;) Renderer: SVG | Canvas Download df &lt;- data.frame(x = 1:10, y = runif(10)) df %&gt;% ggvis(~x, ~y) %&gt;% layer_ribbons() Renderer: SVG | Canvas Download Rectangle set.seed(1014) df &lt;- data.frame(x1 = runif(5), x2 = runif(5), y1 = runif(5), y2 = runif(5)) df %&gt;% ggvis(~x1, ~y1, x2 = ~x2, y2 = ~y2, fillOpacity := 0.1) %&gt;% layer_rects() Renderer: SVG | Canvas Download Text df &lt;- data.frame(x = 3:1, y = c(1, 3, 2), label = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) df %&gt;% ggvis(~x, ~y, text := ~label) %&gt;% layer_text(fontSize := 50) Renderer: SVG | Canvas Download 7.4.2 Compound layers df &lt;- data.frame(x = sin(t), y = cos(t)) df %&gt;% ggvis(~x, ~y) %&gt;% layer_paths() Renderer: SVG | Canvas Download df %&gt;% ggvis(~x, ~y) %&gt;% layer_lines() Renderer: SVG | Canvas Download mtcars %&gt;% ggvis(~mpg) %&gt;% layer_histograms() Renderer: SVG | Canvas Download mtcars %&gt;% ggvis(~wt, ~mpg) %&gt;% layer_smooths() Renderer: SVG | Canvas Download "],["colors-in-r-chinese-translation.html", "Chapter 8 Colors_in_R_Chinese_translation 8.1 在R中使用颜色", " Chapter 8 Colors_in_R_Chinese_translation Xiaoyan Li Source: http://www.sthda.com/english/wiki/colors-in-r 8.1 在R中使用颜色 在 R 中，颜色可以使用指定名称（例如 col = “red”）或使用十六进制编码（如 col =“#FFCC00”）。您还可以使用其他颜色系统，例如从 R 包 RColorBrewer 中获取的彩色系统。 8.1.1 R自带的指定颜色名称 我们将使用以下自定义 R 函数生成一张包含 R 中可用的颜色名称的图： # 生成一张包含R自带颜色名称的图片 #++++++++++++++++++++++++++++++++++++++++++++ # cl : 要绘制的颜色矢量 # bg: 图片背景 # rot: 字体旋转角度 # usage = showCols(bg=&quot;gray33&quot;) showCols &lt;- function(cl=colors(), bg = &quot;grey&quot;, cex = 0.75, rot = 30) { m &lt;- ceiling(sqrt(n &lt;-length(cl))) length(cl) &lt;- m*m; cm &lt;- matrix(cl, m) require(&quot;grid&quot;) grid.newpage(); vp &lt;- viewport(w = .92, h = .92) grid.rect(gp=gpar(fill=bg)) grid.text(cm, x = col(cm)/m, y = rev(row(cm))/m, rot = rot, vp=vp, gp=gpar(cex = cex, col = cm)) } 下图包含前60种颜色的名称： # 前60种颜色的名称 showCols(bg=&quot;gray20&quot;,cl=colors()[1:60], rot=30, cex=0.9) # 使用颜色名称绘制柱状图 barplot(c(2,5), col=c(&quot;chartreuse&quot;, &quot;blue4&quot;)) 要查看 R 的所有内置颜色名称（n = 657），请使用以下 R 代码： showCols(cl= colors(), bg=&quot;gray33&quot;, rot=30, cex=0.75) 8.1.2 使用十六进制编码指定颜色 颜色可以通过十六进制编码指定，例如“#FFC00” （来源：http://www.visibone.com） # 用十六进制编码绘制柱状图 barplot(c(2,5), col=c(&quot;#009999&quot;, &quot;#0000FF&quot;)) 8.1.3 使用 RColorBrewer 调色盘 你需要安装 RColorBrewer 包： # install.packages(&quot;RColorBrewer&quot;) 与 RColorBrewer 包关联的调色板可以使用 display.brewer.all（）绘制，如下： library(&quot;RColorBrewer&quot;) display.brewer.all() 调色板有3种类型：循序、发散和定性。 循序调色板适合用于从低到高（梯度）的有序数据。调色板名称分别是是： Blues, BuGn, BuPu, GnBu, Greens, Greys, Oranges, OrRd, PuBu, PuBuGn, PuRd, Purples, RdPu, Reds, YlGn, YlGnBu YlOrBr, YlOrRd。 发散调色板重点强调了数据范围的两极和中间值。调色板分别有：BrBG, PiYG, PRGn, PuOr, RdBu, RdGy, RdYlBu, RdYlGn, Spectral。 定性调色板最适合表示名义数据或分类数据，并不表明群体之间的幅度差异。调色板名称是： Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3。 你也可以指定查看单个的RColorBrewer调色盘： # 查看单个调色板 display.brewer.pal(n = 8, name = &#39;RdBu&#39;) # 查看单个调色板中颜色的十六进制编码 brewer.pal(n = 8, name = &quot;RdBu&quot;) ## [1] &quot;#B2182B&quot; &quot;#D6604D&quot; &quot;#F4A582&quot; &quot;#FDDBC7&quot; &quot;#D1E5F0&quot; &quot;#92C5DE&quot; &quot;#4393C3&quot; ## [8] &quot;#2166AC&quot; # 用 RColorBrewer 绘制柱状图 barplot(c(2,5,7), col=brewer.pal(n = 3, name = &quot;RdBu&quot;)) 8.1.4 使用 Wes Anderson 调色盘 此调色板可以安装和加载如下： # 安装 # install.packages(&quot;wesanderson&quot;) # 加载 library(wesanderson) 提供调色盘如下： 使用调色板： # 一个简单的柱状图 barplot(c(2,5,7), col=wes_palette(n=3, name=&quot;GrandBudapest1&quot;)) library(ggplot2) ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point(size = 2) + scale_color_manual(values = wes_palette(n=3, name=&quot;GrandBudapest1&quot;)) 8.1.5 创建一个n个连续颜色的矢量 你也可以使用函数rainbow(n), heat.colors(n), terrain.colors(n), topo.colors(n), and cm.colors(n)创建一个包含n个连续的颜色的矢量。 # 使用彩虹的颜色 barplot(1:5, col=rainbow(5)) # 使用热量图的颜色 barplot(1:5, col=heat.colors(5)) # 使用 terrain.colors barplot(1:5, col=terrain.colors(5)) # 使用 topo.colors barplot(1:5, col=topo.colors(5)) # 使用 cm.colors barplot(1:5, col=cm.colors(5)) "],["managing-data-frames-with-dplyr-package-in-chinese.html", "Chapter 9 Managing Data Frames with dplyr Package in Chinese 9.1 Short Description of My Contribution 9.2 数据表 9.3 dplyr包 9.4 dplyr语法 9.5 安装dplyr包 9.6 select() 9.7 filter() 9.8 arrange() 9.9 rename() 9.10 mutate() 9.11 group_by() 9.12 %&gt;% 9.13 总结 9.14 Cited Resourses", " Chapter 9 Managing Data Frames with dplyr Package in Chinese Haoyue Qi library(dplyr) 9.1 Short Description of My Contribution The dplyr package is a very useful package in R for manipulating data frame, and there are many students in China interested in data science and R. However, it is difficult to find a good tutorial for dplyr package in Chinese online. Therefore, my community contribution is that I translate book “R Programming for Data Science”’s 13th chapter “Managing Data Frames with the dplyr package” into Chinese. 9.2 数据表 数据表在统计学和R中是一个核心的数据结构。一个数据表的基础结构是：每一行代表一个观测数据，每一列代表一个变量或观测数据的一个特征。R对数据表有一个内部实现，并且这会是你最常用的。然而，CRAN上会有一些其他实现数据表的包，这些包通过使用关系型数据库的概念可以允许你操作非常非常大的数据表(但是我们在这里不会讨论)。 因为管理数据表的重要性，有好的工具去管理数据表非常重要。在之前的章节中我们已经讨论过了一些工具如subset()函数，还有使用操作符[和$去提取部分数据表。然而，还有一些其他的操作，如过滤，排序，折叠，这些操作在R中非常繁琐，并且语法不是很直观。dplyr包被设计的目的就是去减轻这些问题，并提供一组高度优化过的函数，专门用于操作数据表。 9.3 dplyr包 dplyr包由Rstudio的Hadley Wickham开发，并且dplyr包是他开发的另一个包plyr包的优化精简版本。dplyr包并没有为R提供新的功能。换句话来说就是，dplyr包能做的所有事情base R都可以做，但dplyr包大幅度简化了base R的繁琐操作。 dplyr包的一个重要贡献是它为数据操作和操作数据表提供了一种“语法”(特别是动词)。通过这种语法，你可以与其他懂这种语法的人轻松地交流你对数据表做了什么。这很有用因为它为数据操作提供了一种抽象，这种抽象是之前不存在的。另一个有用的贡献是dolyr函数非常的快，因为其中很多核心操作使用C++编码的。 9.4 dplyr语法 dplyr包提供的一些核心“动词”有： select: 返回数据表的一部分列。 filter: 基于逻辑条件提取数据表的一部分行。 arrange: 重新排列数据表的行。 rename: 重新命名数据表的变量。 mutate: 添加一个新变量/列。或改变一个现有的变量。 summarise/summarize: 生成数据表中不同变量的统计数据。 %&gt;%: 管道操作符，用于连接多个动词操作形成一个管道。 dplyr包有一些它可以利用的自己的数据类型。例如，有一个方便的print函数可以防止你打印很多的数据在控制台里。大多数时间里，这些额外的数据类型对用户是透明的，所以用户不需要去担心。 9.4.1 通用dplyr函数属性 所有我们这章讨论的函数都有一些共同的特点。例如: 第一个参数是数据表。 后续的参数描述了对数据表做什么，并且你可以直接指定数据表中的列，不需要使用$操作符(直接用列名即可)。 函数的返回结果是一个新的数据表。 数据表必须有正确的格式和注释。特别是，数据必须是整洁的(http://www.jstatsoft.org/v59/i10/paper)。简短来说，整洁的意思是必须每行一个观测数据，并且每列代表一个特征。 9.5 安装dplyr包 dplyr包可以通过CRAN安装，也可以使用devtools包和install_github()函数通过GitHub安装。GitHub仓库通常有包的最新版本。 通过CRAN安装，可运行如下代码 install.packages(“dplyr”) 通过GitHub安装，可运行如下代码 install_github(“hadley/dplyr”) 安装完包之后，你需要使用library()函数把它载入到R会话中。 library(dplyr) 你有可能会看到一些警告当包被载入的时候因为dplyr包中有一些函数的名字跟其他包中的一些函数的名字一样。目前为止你可以忽略这些警告。 9.6 select() 这一章节的例子我们用的是一组数据包含芝加哥的空气污染和温度数据。数据网址是http://www.biostat.jhsph.edu/~rpeng/leanpub/rprog/chicago_data.zip。 解压文件后，你可以把数据加载到R中通过readRDS()函数。 rds &lt;- tempfile() download.file(&quot;http://www.biostat.jhsph.edu/~rpeng/leanpub/rprog/chicago_data.zip&quot;,rds) chicago &lt;- readRDS(gzcon(unz(rds, &quot;chicago.rds&quot;))) 你可以看到数据集的一些基础特点通过dim()和str()函数。 dim(chicago) ## [1] 6940 8 str(chicago) ## &#39;data.frame&#39;: 6940 obs. of 8 variables: ## $ city : chr &quot;chic&quot; &quot;chic&quot; &quot;chic&quot; &quot;chic&quot; ... ## $ tmpd : num 31.5 33 33 29 32 40 34.5 29 26.5 32.5 ... ## $ dptp : num 31.5 29.9 27.4 28.6 28.9 ... ## $ date : Date, format: &quot;1987-01-01&quot; &quot;1987-01-02&quot; ... ## $ pm25tmean2: num NA NA NA NA NA NA NA NA NA NA ... ## $ pm10tmean2: num 34 NA 34.2 47 NA ... ## $ o3tmean2 : num 4.25 3.3 3.33 4.38 4.75 ... ## $ no2tmean2 : num 20 23.2 23.8 30.4 30.3 ... select()函数可以被用作去选择你想关注的数据表的列。通常来说，你会有一个很大的数据表包含所有的数据，但是分析只需要一部分变量或观测数据。select()函数允许你获得一些你需要的列。 假设我们只想要前3列。有几个方法可以做到。例如我们可以用数值索引。但是我们也可以直接用列名。 names(chicago)[1:3] ## [1] &quot;city&quot; &quot;tmpd&quot; &quot;dptp&quot; subset &lt;- select(chicago, city:dptp) head(subset) ## city tmpd dptp ## 1 chic 31.5 31.500 ## 2 chic 33.0 29.875 ## 3 chic 33.0 27.375 ## 4 chic 29.0 28.625 ## 5 chic 32.0 28.875 ## 6 chic 40.0 35.125 注意，一般来说:不可以用于名字或字符串，但在select()函数里面，你可以把它用于指定一个范围的变量名。 你也可以不要一些变量通过使用负号在select()函数中。通过select()你可以做 select(chicago, -(city:dptp)) 这句话的意思是包含所有变量除了变量city到dptp。同样意思的代码用base R编写为 i &lt;- match(&quot;city&quot;, names(chicago)) j &lt;- match(&quot;dptp&quot;, names(chicago)) head(chicago[, -(i:j)]) ## date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2 ## 1 1987-01-01 NA 34.00000 4.250000 19.98810 ## 2 1987-01-02 NA NA 3.304348 23.19099 ## 3 1987-01-03 NA 34.16667 3.333333 23.81548 ## 4 1987-01-04 NA 47.00000 4.375000 30.43452 ## 5 1987-01-05 NA NA 4.750000 30.33333 ## 6 1987-01-06 NA 48.00000 5.833333 25.77233 这种写法并不直观。 select()函数也允许一个特殊的语法，这种语法可以允许你指定列名通过模式。例如，你想要所有的变量结尾是“2”，我们可以做 subset &lt;- select(chicago, ends_with(&quot;2&quot;)) str(subset) ## &#39;data.frame&#39;: 6940 obs. of 4 variables: ## $ pm25tmean2: num NA NA NA NA NA NA NA NA NA NA ... ## $ pm10tmean2: num 34 NA 34.2 47 NA ... ## $ o3tmean2 : num 4.25 3.3 3.33 4.38 4.75 ... ## $ no2tmean2 : num 20 23.2 23.8 30.4 30.3 ... 或者我们想要所有的变量开头是“d”，我们可以做 subset &lt;- select(chicago, starts_with(&quot;d&quot;)) str(subset) ## &#39;data.frame&#39;: 6940 obs. of 2 variables: ## $ dptp: num 31.5 29.9 27.4 28.6 28.9 ... ## $ date: Date, format: &quot;1987-01-01&quot; &quot;1987-01-02&quot; ... 你也可以用正则表达式。请看帮助文档(?select)获取更多细节。 9.7 filter() filter()函数可以被用作获取数据表的一部分行。这个函数跟base R中的subset()函数一样，但比subset()函数快。 假设我们想要去获取chicago数据表的一些行，这些行的PM2.5大于30，我们可以做 chic.f &lt;- filter(chicago, pm25tmean2 &gt; 30) str(chic.f) ## &#39;data.frame&#39;: 194 obs. of 8 variables: ## $ city : chr &quot;chic&quot; &quot;chic&quot; &quot;chic&quot; &quot;chic&quot; ... ## $ tmpd : num 23 28 55 59 57 57 75 61 73 78 ... ## $ dptp : num 21.9 25.8 51.3 53.7 52 56 65.8 59 60.3 67.1 ... ## $ date : Date, format: &quot;1998-01-17&quot; &quot;1998-01-23&quot; ... ## $ pm25tmean2: num 38.1 34 39.4 35.4 33.3 ... ## $ pm10tmean2: num 32.5 38.7 34 28.5 35 ... ## $ o3tmean2 : num 3.18 1.75 10.79 14.3 20.66 ... ## $ no2tmean2 : num 25.3 29.4 25.3 31.4 26.8 ... 你可以看到返回的数据表只有194行。pm25tmean2变量的分布是 summary(chic.f$pm25tmean2) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 30.05 32.12 35.04 36.63 39.53 61.50 我们可以放很复杂的逻辑链在filter()函数里。这样我们就可以得到PM2.5大于30并且温度大于80华氏度的行。 chic.f &lt;- filter(chicago, pm25tmean2 &gt; 30 &amp; tmpd &gt; 80) select(chic.f, date, tmpd, pm25tmean2) ## date tmpd pm25tmean2 ## 1 1998-08-23 81 39.60000 ## 2 1998-09-06 81 31.50000 ## 3 2001-07-20 82 32.30000 ## 4 2001-08-01 84 43.70000 ## 5 2001-08-08 85 38.83750 ## 6 2001-08-09 84 38.20000 ## 7 2002-06-20 82 33.00000 ## 8 2002-06-23 82 42.50000 ## 9 2002-07-08 81 33.10000 ## 10 2002-07-18 82 38.85000 ## 11 2003-06-25 82 33.90000 ## 12 2003-07-04 84 32.90000 ## 13 2005-06-24 86 31.85714 ## 14 2005-06-27 82 51.53750 ## 15 2005-06-28 85 31.20000 ## 16 2005-07-17 84 32.70000 ## 17 2005-08-03 84 37.90000 只有17个观测数据两个条件都满足。 9.8 arrange() arrange()函数被用于根据一个变量重新排序数据表的行。重新排列数据表的行的同时保持其他列的顺序对于R来说是很难的。arrange()函数极大简化了这一过程。 这里我们可以通过date变量排序数据表，所以第一行是最早的观测数据，最后一行是最迟的观测数据。 chicago &lt;- arrange(chicago, date) 现在我们可以检查前几行 head(select(chicago, date, pm25tmean2), 3) ## date pm25tmean2 ## 1 1987-01-01 NA ## 2 1987-01-02 NA ## 3 1987-01-03 NA 和最后几行 tail(select(chicago, date, pm25tmean2), 3) ## date pm25tmean2 ## 6938 2005-12-29 7.45000 ## 6939 2005-12-30 15.05714 ## 6940 2005-12-31 15.00000 列也可以以降序重新排序通过用desc()操作符。 chicago &lt;- arrange(chicago, desc(date)) 看看降序排序的前三行和后三行。 head(select(chicago, date, pm25tmean2), 3) ## date pm25tmean2 ## 1 2005-12-31 15.00000 ## 2 2005-12-30 15.05714 ## 3 2005-12-29 7.45000 tail(select(chicago, date, pm25tmean2), 3) ## date pm25tmean2 ## 6938 1987-01-03 NA ## 6939 1987-01-02 NA ## 6940 1987-01-01 NA 9.9 rename() 重新命名数据表的一个变量是非常难得在R中。rename()函数被设计让这个过程变得简单。 这里你可以看到chicago数据表的前5个变量名。 head(chicago[, 1:5], 3) ## city tmpd dptp date pm25tmean2 ## 1 chic 35 30.1 2005-12-31 15.00000 ## 2 chic 36 31.0 2005-12-30 15.05714 ## 3 chic 35 29.4 2005-12-29 7.45000 dptp列应该代表露点温度，pm25tmean2列提供了PM2.5数据。然而，这些名字非常模糊，所以它们应该被重新命名让它们更容易被理解。 chicago &lt;- rename(chicago, dewpoint = dptp, pm25 = pm25tmean2) head(chicago[, 1:5], 3) ## city tmpd dewpoint date pm25 ## 1 chic 35 30.1 2005-12-31 15.00000 ## 2 chic 36 31.0 2005-12-30 15.05714 ## 3 chic 35 29.4 2005-12-29 7.45000 rename()函数里的语法是把新名字放在等号的左边，把旧名字放在等号的右边。 你可以尝试如何用base R完成重命名任务。 9.10 mutate() mutate()函数存在的目的是计算数据表中变量的转换。通常来说，你想要根据一个存在的变量创造一个新变量。mutate()可以简洁的帮你完成这个任务。 例如，对于空气污染数据，我们经常想减去平均数从而减小数据。这样我们就可以看出某天的空气污染是高于还是低于平均值。 这里我们创造一个pm25detrend变量通过从pm25变量里减去平均数。 chicago &lt;- mutate(chicago, pm25detrend = pm25 - mean(pm25, na.rm = TRUE)) head(chicago) ## city tmpd dewpoint date pm25 pm10tmean2 o3tmean2 no2tmean2 ## 1 chic 35 30.1 2005-12-31 15.00000 23.5 2.531250 13.25000 ## 2 chic 36 31.0 2005-12-30 15.05714 19.2 3.034420 22.80556 ## 3 chic 35 29.4 2005-12-29 7.45000 23.5 6.794837 19.97222 ## 4 chic 37 34.5 2005-12-28 17.75000 27.5 3.260417 19.28563 ## 5 chic 40 33.6 2005-12-27 23.56000 27.0 4.468750 23.50000 ## 6 chic 35 29.6 2005-12-26 8.40000 8.5 14.041667 16.81944 ## pm25detrend ## 1 -1.230958 ## 2 -1.173815 ## 3 -8.780958 ## 4 1.519042 ## 5 7.329042 ## 6 -7.830958 还有一个transmute()函数，所做的事情跟mutate()函数一样，但是会去掉所有没有转换的变量。 这里我们减小了PM10和ozone变量。 head(transmute(chicago, pm10detrend = pm10tmean2 - mean(pm10tmean2, na.rm = TRUE), o3detrend = o3tmean2 - mean(o3tmean2, na.rm = TRUE))) ## pm10detrend o3detrend ## 1 -10.395206 -16.904263 ## 2 -14.695206 -16.401093 ## 3 -10.395206 -12.640676 ## 4 -6.395206 -16.175096 ## 5 -6.895206 -14.966763 ## 6 -25.395206 -5.393846 注意返回表只有2列。 9.11 group_by() group_by()函数用于从数据表中根据一个变量生成统计数据。例如，在这个空气污染数据集中，你想要知道每年平均PM2.5值是多少。所以层是year，year可以从date变量里获得。在与group_by()函数结合使用时，我们经常使用summarize()函数。 这里基本的操作是通过group_by()根据一个变量分割数据表，然后再应用一个summary函数在这些子集上。 首先，你可以创造一个year变量通过as.POSIXlt()。 chicago &lt;- mutate(chicago, year = as.POSIXlt(date)$year + 1900) 现在你可以创建一个新表，新表根据year分割了原数据表。 years &lt;- group_by(chicago, year) 最终，你可以用summarize()函数计算数据表中每一年的统计数据。 summarize(years, pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2, na.rm = TRUE), no2 = median(no2tmean2, na.rm = TRUE), .groups = &quot;drop&quot;) ## # A tibble: 19 x 4 ## year pm25 o3 no2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1987 NaN 63.0 23.5 ## 2 1988 NaN 61.7 24.5 ## 3 1989 NaN 59.7 26.1 ## 4 1990 NaN 52.2 22.6 ## 5 1991 NaN 63.1 21.4 ## 6 1992 NaN 50.8 24.8 ## 7 1993 NaN 44.3 25.8 ## 8 1994 NaN 52.2 28.5 ## 9 1995 NaN 66.6 27.3 ## 10 1996 NaN 58.4 26.4 ## 11 1997 NaN 56.5 25.5 ## 12 1998 18.3 50.7 24.6 ## 13 1999 18.5 57.5 24.7 ## 14 2000 16.9 55.8 23.5 ## 15 2001 16.9 51.8 25.1 ## 16 2002 15.3 54.9 22.7 ## 17 2003 15.2 56.2 24.6 ## 18 2004 14.6 44.5 23.4 ## 19 2005 16.2 58.8 22.6 summarize()返回了一个数据表，year是第一列，然后是pm25, o3, 和no2的年平均数。 在一个更复杂的例子里，我们想要知道在各个pm25分位数的区间里，o3和no2的平均是是多少。一个更简便的方法是通过回归模型，但是我们也可以用group_by()和summarize()很快的实现。 首先，我们可以创造一个pm25的类别变量，把PM25分成5等份。 qq &lt;- quantile(chicago$pm25, seq(0, 1, 0.2), na.rm = TRUE) chicago &lt;- mutate(chicago, pm25.quint = cut(pm25, qq)) 现在我们可以通过pm25.quint变量聚合数据表。 quint &lt;- group_by(chicago, pm25.quint) 最终，我们可以计算o3和no2的平均值。 summarize(quint, o3 = mean(o3tmean2, na.rm = TRUE), no2 = mean(no2tmean2, na.rm = TRUE), .groups = &quot;drop&quot;) ## # A tibble: 6 x 3 ## pm25.quint o3 no2 ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (1.7,8.7] 21.7 18.0 ## 2 (8.7,12.4] 20.4 22.1 ## 3 (12.4,16.7] 20.7 24.4 ## 4 (16.7,22.6] 19.9 27.3 ## 5 (22.6,61.5] 20.3 29.6 ## 6 &lt;NA&gt; 18.8 25.8 根据表，看上去pm25和o3没有什么关系，但pm25和no2正相关。更复杂的统计模型可以帮助你给出更准确的答案，但用dplyr函数也可以给出一个还不错的答案。 9.12 %&gt;% 管道操作符%&gt;%可以非常方便的连接多个dplyr函数。注意上文中每次我们想要应用多于一个函数的时候，代码会有一系列嵌套函数，非常难以阅读，例如: third(second(first(x))) 嵌套不是一个自然的方法去思考一系列操作。%&gt;%操作符允许你去从左到右连接操作。 例如: first(x) %&gt;% second %&gt;% third 拿上一章节我们计算o3和no2平均数的例子为例。我们需要做: 1. 创造一个新变量pm25.quint 2. 根据新变量分割数据表 3. 在每个分割组中计算o3和no2的平均数 这可以用如下的单个R表达式做到 mutate(chicago, pm25.quint = cut(pm25, qq)) %&gt;% group_by(pm25.quint) %&gt;% summarize(o3 = mean(o3tmean2, na.rm = TRUE), no2 = mean(no2tmean2, na.rm = TRUE), .groups = &quot;drop&quot;) ## # A tibble: 6 x 3 ## pm25.quint o3 no2 ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (1.7,8.7] 21.7 18.0 ## 2 (8.7,12.4] 20.4 22.1 ## 3 (12.4,16.7] 20.7 24.4 ## 4 (16.7,22.6] 19.9 27.3 ## 5 (22.6,61.5] 20.3 29.6 ## 6 &lt;NA&gt; 18.8 25.8 用这种方式我们不需要创造一堆暂时变量，也不需要用一堆嵌套函数。 注意到在上面代码中，我们把chicago数据表放在了mutate()的第一个参数上，之后我们不再需要把数据表放在group_by()和summarize()的第一个参数上。当我们用%&gt;%的时候，管道中之前元素的输出值会成为第一个参数。 另一个例子是计算每月的平均污染水平。这对查看数据是否有季节性趋势很有用。 mutate(chicago, month = as.POSIXlt(date)$mon + 1) %&gt;% group_by(month) %&gt;% summarize(pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2, na.rm = TRUE), no2 = median(no2tmean2, na.rm = TRUE), .groups = &quot;drop&quot;) ## # A tibble: 12 x 4 ## month pm25 o3 no2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 17.8 28.2 25.4 ## 2 2 20.4 37.4 26.8 ## 3 3 17.4 39.0 26.8 ## 4 4 13.9 47.9 25.0 ## 5 5 14.1 52.8 24.2 ## 6 6 15.9 66.6 25.0 ## 7 7 16.6 59.5 22.4 ## 8 8 16.9 54.0 23.0 ## 9 9 15.9 57.5 24.5 ## 10 10 14.2 47.1 24.2 ## 11 11 15.2 29.5 23.6 ## 12 12 17.5 27.7 24.5 这里我们可以看到o3在冬天会少，在夏天会多。然而no2在冬天会多，在夏天会少。 9.13 总结 dplyr包提供了一些简洁的操作用于管理数据表。用这些函数我们可以做很多复杂的操作用一点点代码。特别是，我们经常可以用group_by()和summarize()函数开始我们的探索性数据分析。 当你学会了dplyr的语法后，还有一些其他好处。 dplyr可以和其他数据表后端如SQL数据库一起工作。通过DBI包有一个用于关系型数据库的SQL接口。 dplyr可以和data.table包集成用于快速的操作很大的表。 dplyr包可以简单快速的管理数据表。你很少会同时获得这样的组合。 9.14 Cited Resourses Peng, Roger D.. “13. Managing Data Frames with the dplyr package.” “R Programming for Data Science”, 2020, pp.52-64. "],["introduction-to-rstudio-in-portuguese.html", "Chapter 10 Introduction to Rstudio in Portuguese", " Chapter 10 Introduction to Rstudio in Portuguese Barbara Bettencourt For my community contribution I translated a document on an introduction to Rstudio from Princeton University to Portuguese. You can find the pdf here: https://github.com/barbarabettencourt/community_contribution/blob/main/RStudio101Translation.pdf "],["creating-r-packages.html", "Chapter 11 Creating R Packages", " Chapter 11 Creating R Packages Sam Gabor Creating custom R packages allows users to exchange code logic and data effortlessly. In addition, even if R packages are not shared with others, they still provide utility for the R user because they group related functionality into clean, easily maintained and tested units. I created a tutorial that illustrates the creation of a non-trivial R package covering all the steps that constitute a good work flow. It culminates in publishing the created package on GitHub where it can be shared with other users using devtools::install_github(\"atsats/PCD\"). The finished package as well as the Tutorial markdown, html and pdf files can be found here: https://github.com/atsats/PCD "],["getting-data-using-apis.html", "Chapter 12 Getting data using APIs", " Chapter 12 Getting data using APIs Melissa Bischoff For my community contribution project I created a tutorial on how to use APIs to get data. API integrations are an easy and useful way to pull data from the internet before resorting to web scraping. A lot of companies and services have APIs available, some are free for public use and some are for paying customers. In my tutorial I did three examples of getting data using APIs - one in R and two in Python. The first example is in R and uses the httr package. It accesses the github job posting API, which does not require authentication. The second example is the same as the first but in Python and uses the requests package. The third example is also in Python with the requests package but uses the Spotify API which does require authentication. The tutorial includes information about what APIs are focusing on the GET and POST method, examples of getting data from APIs with and without authentication, and helpful tricks along the way. "],["zoom-session-in-finance-and-data-science.html", "Chapter 13 Zoom session in Finance and Data-Science", " Chapter 13 Zoom session in Finance and Data-Science Minwoo Choi This Zoom session was held on Wed (Mar 18) at 4:00 EST (Food for thought) Systemic approach and its application in finance has a very long history. Systemic trading, ML driven factor / alpha engine has been around quite a while even though no one really knows what is actually going on in the industry, it is a very secretive world ! Financial industry, especially trading and investment management business, is an extremely closed community that is entirely competition driven. Hence, it is very rare to experience other company’s in-house research and models. Also, in my opinion, there is a huge gap between what we learn in school and cutting-edge models being used in secretive quantitative trading firms. This is one reason I am not a big fan of finance anymore. Based on my short experience outside of the financial industry, I feel that other data science communities are more open and collaboration based. (e.g. think about Stackoverflow… and TensorFlow is free, but Bloomberg terminal costs 30k per year) Second big difference is, data in finance is not static and much more vulnerable to a sudden regime change. For example, global macro situations, market liquidity can be purely driven by sudden change in central bank policy. Unlike natural phenomena, the market is man-made and driven by unnatural forces. Market intervention, manipulation is more often than outsiders believe. So, I hear many times (even though mine is at best second hand opinions) that looking into ‘mean-reversion’, ‘overbought, oversold’ indicators will provide a better opportunity than just looking at ‘static’ price data. Darko Matovski, CEO of CausaLens, explained two major pitfalls of applying ML in finance data during the AI and DS in Trading event held this week. ‘Let’s imagine applying deep-learning to US mortgage data that had never failed for 100 years, and make a prediction. And recall what happened during a financial crisis in a sudden shift in price dynamics.’ He also emphasized that finance data frequently shows sudden regime change, and having a proper ‘state status’ setup is crucial for reinforcement learning. (Of course, he did not reveal his way of building a better simulator, his proprietary models are reserved for clients only !) Also, another common problem in ML in finance is people tend to confuse ‘correlation’ to ‘causality’. Jeff Wecker, CTO of TwoSigma, made another good point during the conference about financial data. What is special about financial data and its usefulness? In a typical ML or data-science problem, we strive to make a better prediction using our data. One major problem of using data for solving financial problems in pursuit of maximizing profit is decaying value of data. First user who developed a fancy data model takes the most benefit, and then naturally the industry is being crowded as other users jump in and make a similar prediction based on the same data. Therefore, the benefit of making a similar prediction and solving a similar financial problem is rapidly decaying. This is not always the case in other technology fields. Of course, there’s lots of areas where we can apply data-science, ML techniques in finance. Any classification, NLP can help operations perform better and save costs. Document sorting, classification, or making credit decisions, providing a financial planning solution can be rather easily automated using ML techniques. One other interesting area could be using K-mean clustering for categorizing financial assets into multiple groups. This simple technique could be used for liquidity monitoring based on daily trading volume or volatility, also for categorizing assets into different risk groups for better portfolio management as well. "],["github-initial-setup.html", "Chapter 14 Github initial setup 14.1 GitHub Actions 14.2 DESCRIPTION file", " Chapter 14 Github initial setup Joyce Robbins Create a new repository. (For cc21 I started with a new repo on GitHub since I wanted the main branch to be called main and that did not seem possible with usethis functions or RStudio \" Copy the following files from the previous version and edit as necessary. (Search for name of previous repo to catch all instances.) _bookdown.yml _common.R _output.yml appendix_initial_setup.Rmd appendix_pull_request_tutorial.Rmd DESCRIPTION index.Rmd sample_project.Rmd /.github /resources/sample_project /resources/tutorial_pull_request_mergers 14.1 GitHub Actions 14.1.1 Secrets https://medium.com/@delucmat/how-to-publish-bookdown-projects-with-github-actions-on-github-pages-6e6aecc7331e Secret #1: Create a token here https://github.com/settings/tokens and paste it in a secret in the repo named GH_PAT Secret #2: Add a Secret called EMAIL with GitHub email See: https://github.com/r-lib/actions/tree/master/examples#managing-secrets 14.1.2 Create a gh-pages branch: https://jiafulow.github.io/blog/2020/07/09/create-gh-pages-branch-in-existing-repo/ (May happen automatically???) 14.1.3 GitHub Pages in repo settings (May happen automatically???) 14.2 DESCRIPTION file Need a better process… Downloaded submissions from CourseWorks Create DESCRIPTION file. Add add dependencies with projthis::proj_update_deps() https://twitter.com/ijlyttle/status/1370776366585614342 Add these Imports to the real DESCRIPTION file. Found problematic packages by looking at reverse dependencies of the packages that failed to install: devtools::revdep() Also used pak::pkg_deps_tree() Problems: magick rJava dependency of qdap "],["tutorial-for-pull-request-mergers.html", "Chapter 15 Tutorial for pull request mergers 15.1 General 15.2 Check branch 15.3 Examine files that were added or modified 15.4 Check .Rmd filename 15.5 Check .Rmd file contents 15.6 Request changes 15.7 Merge the pull request", " Chapter 15 Tutorial for pull request mergers 15.1 General The following is a checklist of steps to perform before merging the pull request. At any point, if you’re not sure what to do, request a review from one of the PR leaders. 15.2 Check branch PR should be submitted from a non-main branch. If PR was submitted from the main branch, provide these instructions on how to fix the problem: Close this PR. Follow the instructions here for forgetting to branch if you committed and pushed to GitHub: https://edav.info/github#fixing-mistakes If you have trouble with 2., then delete the local folder of the cc21 project and reclone. (In other words, start over.) Open a new PR. 15.3 Examine files that were added or modified There should be only ONE .Rmd file. All of the additional resources should be in the resources/&lt;project_name&gt;/ folder. There should be no other files in the root directory besides the .Rmd file. 15.4 Check .Rmd filename The .Rmd filename should be words only and joined with underscores, no white space. (Update: It does not need to be the same as the branch name.) The .Rmd filename can only contain lowercase letters. (Otherwise the filenames do not sort nicely on the repo home page.) 15.5 Check .Rmd file contents The file should not contain a YAML header nor a --- line. The second line should be blank, followed by the author name(s). The first line should start with a single hashtag #, followed by a single whitespace, and then the title. There should be no additional single hashtag headers in the chapter. (If there are, new chapters will be created.) Other hashtag headers should not be followed by numbers since the hashtags will create numbered subheadings. Correct: ## Subheading. Incorrect: ## 3. Subheading. If the file contains a setup chunk in .Rmd file, it should not contain a setup label. (The bookdown render will fail if there are duplicate chunk labels.) i.e. use {r, include=FALSE} instead of {r setup, include=FALSE}. See sample .Rmd Links to internal files must contain resources/&lt;project_name&gt;/ in the path, such as: ![Test Photo](resources/sample_project/election.jpg) The file should not contain any install.packages(), write functions, setwd(), or getwd(). If there’s anything else that looks odd but you’re not sure, assign jtr13 to review and explain the issue. 15.6 Request changes If there are problems with any of the checks listed above, explain why the pull request cannot be merged and request changes by following these steps: Then, add a changes requested label to this pull request. Your job for this pull request is done for now. Once contributors fix their requests, review again and either move forward with the merge or explain what changes still need to be made. 15.7 Merge the pull request If all is good to go, it’s time to merge the pull request. There are several steps. 15.7.1 Add chapter filename to _bookdown.yml in PR’s branch To access the PR branch: Make sure you are on the PR branch by checking that the PR branch name is shown (not main): Open the _bookdown.yml file. delete everything in the file beginning with rmd_files: [ and then add the name of the new file in single quotes followed by a comma: Why? Because it will be easier to fix the merge conflicts this way. (A better way to do this is to merge main into the PR branch before adding the new file but this can’t be done on GitHub. If there’s interest I will explain how to do this locally.) Save the edited version. Click the resolve conflicts button: Cut the new filename and paste it into the proper location. Then delete the lines with &lt;&lt;&lt;&lt;&lt;&lt;&lt; xxxx, ======= and &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; main. In short, the file should look correct when you’re done. Click the “Marked as resolved” button and then the green “Commit merge” button. 15.7.2 PR Leaders only: Add part names to .Rmd for every first article in part Only do this if you are adding the first chapter in a PART. For every first article of each part, add the chapter name on the top of the .Rmd file, then propose changes. The example is like this. 15.7.3 Merge PR and leave a comment Now comes the final step. If you’re not sure that you did things correctly, assign one of the PR merge leaders or @jtr13 to review before you merge the PR. Go back to the conversation tab of the pull requests page, for example: https://github.com/jtr13/cc20/pull/23#issuecomment-728506101 Leave comments for congratulations 🎉 (type :tada:) and then click on the green button for merge. 15.7.4 Check updated version A successful merge means that the addition file or files were added to the project with no merge conflicts. It does not mean that the book will render and deploy to GitHub pages without issues. After the merge, it will take about 5-10 minutes for GitHub Actions to render the book and deploy the updated version. If there’s a problem I will be notified by email and will address it. In other words, your job is done. However if you’re interested, you can check the progress by clicking Actions at the top of the repo. "]]
